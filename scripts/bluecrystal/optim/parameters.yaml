program: gym_learn_sweep.py
method: bayes
metric:
  name: episode_reward
  goal: maximise
parameters:
  lam:
    values: [0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0]
  gamma:
    values: [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]
  n_batch:
    values: [32, 64, 128, 256]
  n_steps:
    values: [16, 32, 64, 128, 256, 512, 1024, 2048]
  ent_coef:
    distribution: log_uniform
    min: 0.00000001
    max: 0.1
  cliprange:
    values: [0.1, 0.2, 0.3, 0.4]
  noptepochs:
    values: [1, 5, 10, 20, 30, 50]
  learning_rate:
    distribution: log_uniform
    min: 1e-5
    max: 1