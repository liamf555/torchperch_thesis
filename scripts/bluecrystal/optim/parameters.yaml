program: gym_learn_sweep.py
method: bayes
metric:
  name: mean_reward
  goal: maximise
parameters:
  lam:
    distribution: categorical 
    values: [0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0]
  gamma:
    distribution: categorical
    values: [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]
  cliprange:
    distribution: categorical
    values: [0.1, 0.2, 0.3, 0.4]
  noptepochs:
    distribution: categorical
    values: [1, 5, 10, 20, 30, 50]
  learning_rate:
    distribution: log_uniform
    min: -11.512925464970229
    max: 0.0
  # net_arch:
  #   distribution: categorical
  #   values: ["small", "medium"]
  ent_coef:
    distribution: log_uniform
    min: -18.420680743952367
    max: -2.3025850929940455
  batch_size:
    distribution: categorical
    values: [32, 64, 128, 256]
  n_steps:
    distribution: categorical
    values: [16, 32, 64, 128, 256, 512, 1024, 2048]
  
    